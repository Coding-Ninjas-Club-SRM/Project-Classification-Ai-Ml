{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import random\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import boto3\n",
    "import botocore \n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 David_Schwimmer\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "...\n",
    "...\n",
    "Run this cell to load training data\n",
    "...\n",
    "...\n",
    "\"\"\"\n",
    "data = \"./own/*/\"\n",
    "x = []\n",
    "y = []\n",
    "classes = {}\n",
    "to_add = {\"id\": [], \"name\": [], \"insta\": []}\n",
    "#bucket_name = 'cnfacerecog'\n",
    "#bucket = res.Bucket(bucket_name)\n",
    "#keys_in_bucket = [o.key for o in bucket.objects.all()]\n",
    "temp = 0\n",
    "    \n",
    "#num_classes = len(glob.glob(os.path.join(data)))\n",
    "#n = random.randint(0, num_classes)\n",
    "for idx, folder in enumerate(glob.glob(os.path.join(data))):\n",
    "    if idx == 3000:\n",
    "        break\n",
    "    num_pics = len(glob.glob(os.path.join(folder+\"*\")))\n",
    "    if num_pics < 10:\n",
    "        continue\n",
    "    use = glob.glob(os.path.join(folder+\"*\"))[:10]\n",
    "    person_name = folder.split(\"\\\\\")[1]\n",
    "    print(idx, person_name)\n",
    "    classes[idx] = person_name\n",
    "    to_add[\"id\"].append(idx)\n",
    "    to_add[\"name\"].append(person_name)\n",
    "    to_add[\"insta\"].append(\"\")\n",
    "    for f in use:\n",
    "        \"\"\"\n",
    "        file_name = f.split(\"\\\\\")[-1]\n",
    "        bucket_file_name = \"faces_5/\"+str(idx)+\"/\"+file_name \n",
    "        if bucket_file_name in keys_in_bucket:\n",
    "            continue\n",
    "        response = s3.upload_file(f, bucket_name, bucket_file_name)\"\"\"\n",
    "        \n",
    "        pic = cv2.imread(f)\n",
    "        detected_pos = fr.face_locations(pic)\n",
    "        for i in detected_pos:\n",
    "            top, right, bottom, left = i\n",
    "            face_image = pic[top:bottom, left:right]\n",
    "            try:\n",
    "                face_image = cv2.resize(face_image, (256, 256))\n",
    "                face_embedding = fr.face_encodings(face_image)[0]\n",
    "                x.append(face_embedding)\n",
    "                y.append(idx)\n",
    "            except:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(l, name):\n",
    "    with open(\"./saved/\"+name, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(l, fp)\n",
    "        \n",
    "def load_dataset(name):\n",
    "    with open(\"./saved/\"+name, \"rb\") as fp:   # Unpickling\n",
    "        b = pickle.load(fp)\n",
    "    return b;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_x = load_dataset(\"3000_10\")\n",
    "saved_y = load_dataset(\"3000_10_y\")\n",
    "for i in range(0, len(y)):\n",
    "    y[i] += saved_y[-1]+1\n",
    "    saved_y.append(y[i])\n",
    "for i in x:\n",
    "    saved_x.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879 879\n"
     ]
    }
   ],
   "source": [
    "print(len(saved_x), len(saved_y))\n",
    "classes[\"2941\"] = \"David_Schwimmer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not changed\n"
     ]
    }
   ],
   "source": [
    "#IGNORE THIS CELL\n",
    "\n",
    "def updating_csv(df2):\n",
    "    obj = s3.get_object(Bucket=\"cnfacerecog\", Key=\"details.csv\")[\"Body\"]\n",
    "    df = pd.read_csv(obj)\n",
    "    df['insta'] = df['insta'].fillna(\"\")\n",
    "    if not(df.equals(df2)):\n",
    "        df = df.append(df2, ignore_index = True)\n",
    "        csv_buffer = StringIO()\n",
    "        df.to_csv(csv_buffer, index=False)\n",
    "        #res.Object(\"cnfacerecog\", 'details.csv').put(Body=csv_buffer.getvalue())\n",
    "    else:\n",
    "        print(\"Data not changed\")\n",
    "df2 = pd.DataFrame(to_add)\n",
    "updating_csv(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n",
      "1013\n",
      "1021\n",
      "1027\n",
      "1033\n",
      "1043\n",
      "1045\n",
      "1047\n",
      "1059\n",
      "107\n",
      "1072\n",
      "1091\n",
      "1204\n",
      "1207\n",
      "121\n",
      "1237\n",
      "1252\n",
      "1268\n",
      "1270\n",
      "1306\n",
      "1309\n",
      "1314\n",
      "1333\n",
      "1347\n",
      "1382\n",
      "1393\n",
      "1473\n",
      "1476\n",
      "1480\n",
      "1492\n",
      "1536\n",
      "1540\n",
      "1558\n",
      "1559\n",
      "1565\n",
      "1581\n",
      "1589\n",
      "1617\n",
      "1695\n",
      "1696\n",
      "17\n",
      "1704\n",
      "1758\n",
      "1784\n",
      "1835\n",
      "1843\n",
      "1849\n",
      "1854\n",
      "1856\n",
      "1862\n",
      "1865\n",
      "1870\n",
      "189\n",
      "1891\n",
      "1894\n",
      "1911\n",
      "1932\n",
      "1936\n",
      "1940\n",
      "1945\n",
      "1962\n",
      "1964\n",
      "1966\n",
      "197\n",
      "1993\n",
      "1998\n",
      "204\n",
      "210\n",
      "213\n",
      "222\n",
      "223\n",
      "239\n",
      "241\n",
      "272\n",
      "290\n",
      "297\n",
      "300\n",
      "302\n",
      "317\n",
      "335\n",
      "353\n",
      "358\n",
      "370\n",
      "374\n",
      "380\n",
      "384\n",
      "386\n",
      "401\n",
      "417\n",
      "471\n",
      "479\n",
      "481\n",
      "50\n",
      "502\n",
      "506\n",
      "527\n",
      "544\n",
      "550\n",
      "551\n",
      "552\n",
      "562\n",
      "573\n",
      "579\n",
      "58\n",
      "604\n",
      "610\n",
      "619\n",
      "627\n",
      "642\n",
      "706\n",
      "73\n",
      "736\n",
      "744\n",
      "747\n",
      "760\n",
      "781\n",
      "783\n",
      "802\n",
      "816\n",
      "827\n",
      "831\n",
      "843\n",
      "847\n",
      "852\n",
      "875\n",
      "882\n",
      "89\n",
      "896\n",
      "904\n",
      "923\n",
      "942\n",
      "946\n",
      "97\n",
      "673\n",
      "673\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "NOTE: PLSEASE IGNORE THIS CELL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "bucket_name = 'cnfacerecog'\n",
    "bucket = res.Bucket(bucket_name)\n",
    "temp = 0\n",
    "for o in bucket.objects.all():\n",
    "    if o.key.find(\"faces_5/\") != -1:\n",
    "        idx = int(o.key.split(\"/\")[1])\n",
    "        if temp != idx:\n",
    "            temp = idx\n",
    "            print(idx)\n",
    "        pic = s3.get_object(Bucket=bucket_name, Key=o.key) \n",
    "        pic = np.array(Image.open(pic[\"Body\"]))\n",
    "        detected_pos = fr.face_locations(pic)\n",
    "        for i in detected_pos:\n",
    "            top, right, bottom, left = i\n",
    "            face_image = pic[top:bottom, left:right]\n",
    "            try:\n",
    "                face_image = cv2.resize(face_image, (256, 256))\n",
    "                face_embedding = fr.face_encodings(face_image)[0]\n",
    "                x.append(face_embedding)\n",
    "                y.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "print(len(x))\n",
    "print(len(y))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1581', '1473', '2885', '2283', '2173', '370', '1059', '783', '1911', '875', '579', '1932', '58', '627', '374', '2419', '1382', '272', '1945', '831', '544', '2726', '2017', '1268', '197', '2264', '1091', '239', '471', '552', '1045', '2504', '1027', '1558', '1936', '1270', '1835', '802', '213', '2327', '1998', '1784', '2926', '97', '1862', '1207', '1565', '1617', '1894', '843', '2275', '1589', '506', '747', '223', '335', '1033', '2186', '2433', '1964', '2619', '2693', '2730', '2302', '2470', '2755', '760', '816', '550', '1306', '1047', '1309', '386', '2026', '1966', '2751', '297', '73', '2473', '1856', '2043', '2565', '610', '1865', '384', '2285', '2450', '1870', '2915', '551', '481', '189', '2526', '2500', '1204', '604', '401', '1843', '2857', '1072', '852', '1962', '2824', '1476', '573', '479', '317', '121', '210', '744', '2508', '1013', '1237', '736', '1021', '1347', '904', '1540', '1695', '1891', '2199', '1704', '706', '1559', '300', '1333', '527', '619', '946', '204', '1480', '847', '89', '17', '1854', '241', '380', '1393', '222', '2131', '2661', '1314', '358', '502', '562', '417', '1043', '1993', '781', '107', '302', '2687', '1007', '882', '923', '1758', '2501', '50', '1536', '642', '942', '827', '896', '1492', '2210', '2773', '353', '2469', '2685', '1696', '290', '1940', '2940', '1849', '2155', '2055', '1252']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#PLEASE IGNORE THIS CELL\n",
    "\n",
    "\n",
    "def get_class_ids_from_bucket():\n",
    "    bucket_name = 'cnfacerecog'\n",
    "    bucket = res.Bucket(bucket_name)\n",
    "    try:\n",
    "        classes_in_bucket = list(set([o.key.split(\"/\")[1] for o in bucket.objects.all() if o.key != \"details.csv\"]))\n",
    "        classes_in_bucket.remove(\"\")\n",
    "        return classes_in_bucket\n",
    "    except Exception as e:\n",
    "        for o in bucket.objects.all():\n",
    "            print(o.key)\n",
    "    \n",
    "\n",
    "classes_in_bucket = get_class_ids_from_bucket()\n",
    "print(classes_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"classes.json\", \"w\") as outfile:\n",
    "    json.dump(classes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17': 'Abdullah_Gul', '50': 'Adrien_Brody', '121': 'Alejandro_Toledo', '204': 'Alvaro_Uribe', '223': 'Amelie_Mauresmo', '272': 'Andre_Agassi', '290': 'Andy_Roddick', '302': 'Angelina_Jolie', '317': 'Anna_Kournikova', '335': 'Ann_Veneman', '370': 'Ariel_Sharon', '374': 'Ari_Fleischer', '386': 'Arnold_Schwarzenegger', '417': 'Atal_Bihari_Vajpayee', '544': 'Bill_Clinton', '551': 'Bill_Gates', '562': 'Bill_McBride', '573': 'Bill_Simon', '706': 'Britney_Spears', '781': 'Carlos_Menem', '783': 'Carlos_Moya', '831': 'Catherine_Zeta-Jones', '875': 'Charles_Moose', '1047': 'Colin_Powell', '1059': 'Condoleezza_Rice', '1207': 'David_Beckham', '1252': 'David_Nalbandian', '1347': 'Dick_Cheney', '1382': 'Dominique_de_Villepin', '1393': 'Donald_Rumsfeld', '1473': 'Edmund_Stoiber', '1476': 'Eduardo_Duhalde', '1704': 'Fidel_Castro', '1854': 'George_HW_Bush', '1865': 'George_Robertson', '1870': 'George_W_Bush', '1891': 'Gerhard_Schroeder', '1932': 'Gloria_Macapagal_Arroyo', '1940': 'Gonzalo_Sanchez_de_Lozada', '1945': 'Gordon_Brown', '1964': 'Gray_Davis', '1993': 'Guillermo_Coria', '2017': 'Halle_Berry', '2026': 'Hamid_Karzai', '2043': 'Hans_Blix', '2055': 'Harrison_Ford', '2131': 'Hillary_Clinton', '2155': 'Howard_Dean', '2173': 'Hugo_Chavez', '2186': 'Hu_Jintao', '2199': 'Ian_Thorpe', '2210': 'Igor_Ivanov', '2264': 'Jackie_Chan', '2275': 'Jack_Straw', '2283': 'Jacques_Chirac', '2285': 'Jacques_Rogge', '2302': 'James_Blake', '2327': 'James_Kelly', '2419': 'Jason_Kidd', '2433': 'Javier_Solana', '2450': 'Jean-David_Levitte', '2469': 'Jean_Charest', '2470': 'Jean_Chretien', '2473': 'Jeb_Bush', '2500': 'Jennifer_Aniston', '2501': 'Jennifer_Capriati', '2504': 'Jennifer_Garner', '2508': 'Jennifer_Lopez', '2526': 'Jeremy_Greenstock', '2565': 'Jiang_Zemin', '2619': 'Jiri_Novak', '2661': 'Joe_Lieberman', '2685': 'John_Allen_Muhammad', '2687': 'John_Ashcroft', '2693': 'John_Bolton', '2726': 'John_Howard', '2730': 'John_Kerry', '2751': 'John_Negroponte', '2755': 'John_Paul_II', '2773': 'John_Snow', '2824': 'Joschka_Fischer', '2857': 'Jose_Maria_Aznar', '2885': 'Juan_Carlos_Ferrero', '2915': 'Julianne_Moore', '2926': 'Julie_Gerberding', '2940': 'Junichiro_Koizumi', '2941': 'David_Schwimmer'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "class_f = open('classes.json')\n",
    "classes = json.load(class_f)\n",
    "print(dict(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "model = OneVsRestClassifier(SVC(kernel='linear', probability=True, verbose=True, max_iter=3000))\n",
    "#model = OneVsOneClassifier(SVC(kernel='linear', probability=True, verbose=True, max_iter=3000))\n",
    "model.fit(saved_x, saved_y)\n",
    "pickle.dump(model, open(\"./3000_10\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"./3000_10\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17,   50,  121,  204,  223,  272,  290,  302,  317,  335,  370,\n",
       "        374,  386,  417,  544,  551,  562,  573,  706,  781,  783,  831,\n",
       "        875, 1047, 1059, 1207, 1252, 1347, 1382, 1393, 1473, 1476, 1704,\n",
       "       1854, 1865, 1870, 1891, 1932, 1940, 1945, 1964, 1993, 2017, 2026,\n",
       "       2043, 2055, 2131, 2155, 2173, 2186, 2199, 2210, 2264, 2275, 2283,\n",
       "       2285, 2302, 2327, 2419, 2433, 2450, 2469, 2470, 2473, 2500, 2501,\n",
       "       2504, 2508, 2526, 2565, 2619, 2661, 2685, 2687, 2693, 2726, 2730,\n",
       "       2751, 2755, 2773, 2824, 2857, 2885, 2915, 2926, 2940, 2941])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "['17', '50', '121', '204', '223', '272', '290', '302', '317', '335', '370', '374', '386', '417', '544', '551', '562', '573', '706', '781', '783', '831', '875', '1047', '1059', '1207', '1252', '1347', '1382', '1393', '1473', '1476', '1704', '1854', '1865', '1870', '1891', '1932', '1940', '1945', '1964', '1993', '2017', '2026', '2043', '2055', '2131', '2155', '2173', '2186', '2199', '2210', '2264', '2275', '2283', '2285', '2302', '2327', '2419', '2433', '2450', '2469', '2470', '2473', '2500', '2501', '2504', '2508', '2526', '2565', '2619', '2661', '2685', '2687', '2693', '2726', '2730', '2751', '2755', '2773', '2824', '2857', '2885', '2915', '2926', '2940', '2941']\n"
     ]
    }
   ],
   "source": [
    "class_list = list(classes.keys())\n",
    "print(len(class_list))\n",
    "print(class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we go one by one through each test face image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lol\n",
      "Bill_Clinton 0.8673548109600338\n",
      "Face not found!\n",
      "Face not found!\n",
      "David_Schwimmer 0.8041707437431614\n",
      "Jennifer_Aniston 0.8693508829717437\n"
     ]
    }
   ],
   "source": [
    "data = \"./archive/group/*/\"\n",
    "#data = \"../lfw/*/\"\n",
    "for idx, folder in enumerate(glob.glob(os.path.join(data))):\n",
    "    use = glob.glob(os.path.join(folder+\"*\"))\n",
    "    person_name = folder.split(\"\\\\\")[1]\n",
    "    print(idx, person_name)\n",
    "    #classes[idx] = person_name\n",
    "    for f in use:\n",
    "        pic = cv2.imread(f)\n",
    "        try:\n",
    "            face_embedding = fr.face_encodings(pic)[0]\n",
    "            test = np.asarray(face_embedding)\n",
    "            test=  np.reshape(test, (1, -1))\n",
    "            pred = model.predict_proba(test)[0]\n",
    "            if np.max(pred) > 0.7:\n",
    "                print(classes[str(class_list[np.argmax(pred)])], np.max(pred))\n",
    "            elif np.max(pred) > 0.5 :\n",
    "                #added to see what it predicts when highest probability is quite low\n",
    "                #print(classes[str(class_list[np.argmax(pred)])], np.max(pred)) \n",
    "                choose_folder = \"./lfw\\\\\"+classes[str(class_list[np.argmax(pred)])]+\"\\\\*\"\n",
    "                test_pic_path = glob.glob(os.path.join(choose_folder))[0]\n",
    "                test_pic = cv2.imread(test_pic_path)\n",
    "                try:\n",
    "                    test_face_embedding = fr.face_encodings(test_pic)[0]\n",
    "                    results = fr.compare_faces([face_embedding], test_face_embedding)\n",
    "                    if results[0]:\n",
    "                        print(classes[str(class_list[np.argmax(pred)])], np.max(pred)) \n",
    "                    else:\n",
    "                        print(\"Face not found!\")\n",
    "                except Exception as first_e:\n",
    "                    raise(first_e)\n",
    "            else:\n",
    "                print(\"Face not found!\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            raise(e)\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we input all face embeddings in a single array - gives faster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lol\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "data = \"./archive/group/*/\"\n",
    "testx = []\n",
    "for idx, folder in enumerate(glob.glob(os.path.join(data))):\n",
    "    use = glob.glob(os.path.join(folder+\"*\"))\n",
    "    person_name = folder.split(\"\\\\\")[1]\n",
    "    print(idx, person_name)\n",
    "    for f in use:\n",
    "        pic = cv2.imread(f)\n",
    "        try:\n",
    "            all_emb = fr.face_encodings(pic)\n",
    "            for test in all_emb:\n",
    "                test = np.asarray(test)\n",
    "                testx.append(test)\n",
    "        except:\n",
    "            continue\n",
    "print(len(testx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probs = model.predict(testx)\\nfor i in probs:\\n    print(classes[str(i)])'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"probs = model.predict(testx)\n",
    "for i in probs:\n",
    "    print(classes[str(i)])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill_Clinton 0.8673548109600336\n",
      "Bill_Gates 0.724431984996856\n",
      "3. Face not found!\n",
      "Jennifer_Aniston 0.5778182425252121\n",
      "3. Face not found!\n",
      "3. Face not found!\n",
      "David_Schwimmer 0.6541527634603629\n",
      "3. Face not found!\n",
      "3. Face not found!\n",
      "1. Face not found!\n",
      "Jennifer_Aniston 0.865090075415614\n",
      "3. Face not found!\n",
      "1. Face not found!\n",
      "David_Schwimmer 0.7964122744891994\n",
      "David_Schwimmer 0.8041707437431614\n",
      "Jennifer_Aniston 0.871849494529098\n",
      "Jennifer_Aniston 0.8693508829717439\n",
      "Angelina_Jolie 0.8599382568050015\n",
      "Jennifer_Lopez 0.7597069296295129\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict_proba(testx)\n",
    "present = []\n",
    "for idx, pred in enumerate(probs):\n",
    "    if np.max(pred) > 0.7:\n",
    "        print(classes[(class_list[np.argmax(pred)])], np.max(pred))\n",
    "        present.append(class_list[np.argmax(pred)])\n",
    "    elif np.max(pred) > 0.5:\n",
    "        choose_folder = \"./lfw\\\\\"+classes[(class_list[np.argmax(pred)])]+\"\\\\*\"\n",
    "        real_face_embedding = testx[idx]\n",
    "        test_pic_path = glob.glob(os.path.join(choose_folder))[0]\n",
    "        test_pic = cv2.imread(test_pic_path)\n",
    "        try:\n",
    "            test_face_embedding = fr.face_encodings(test_pic)[0]\n",
    "            results = fr.compare_faces([real_face_embedding], test_face_embedding)\n",
    "            if results[0]:\n",
    "                print(classes[(class_list[np.argmax(pred)])], np.max(pred)) \n",
    "                present.append(class_list[np.argmax(pred)])\n",
    "            else:\n",
    "                print(\"1. Face not found!\")\n",
    "                #print(classes[(class_list[np.argmax(pred)])], np.max(pred)) \n",
    "        except Exception as first_e:\n",
    "            print(\"2. Face not found!\")\n",
    "            #print(classes[(class_list[np.argmax(pred)])], np.max(pred)) \n",
    "    else:\n",
    "        print(\"3. Face not found!\")\n",
    "        #print(classes[(class_list[np.argmax(pred)])], np.max(pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2508', '2941', '302', '544', '551', '2500']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present = list(set(present))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jennifer_Lopez\n",
      "David_Schwimmer\n",
      "Angelina_Jolie\n",
      "Bill_Clinton\n",
      "Bill_Gates\n",
      "Jennifer_Aniston\n"
     ]
    }
   ],
   "source": [
    "for i in present:\n",
    "    print(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdullah_Gul 0\n",
      "Adrien_Brody 0\n",
      "Alejandro_Toledo 0\n",
      "Alvaro_Uribe 0\n",
      "Amelie_Mauresmo 0\n",
      "Andre_Agassi 0\n",
      "Andy_Roddick 0\n",
      "Angelina_Jolie 1\n",
      "Anna_Kournikova 0\n",
      "Ann_Veneman 0\n",
      "Ariel_Sharon 0\n",
      "Ari_Fleischer 0\n",
      "Arnold_Schwarzenegger 0\n",
      "Atal_Bihari_Vajpayee 0\n",
      "Bill_Clinton 1\n",
      "Bill_Gates 1\n",
      "Bill_McBride 0\n",
      "Bill_Simon 0\n",
      "Britney_Spears 0\n",
      "Carlos_Menem 0\n",
      "Carlos_Moya 0\n",
      "Catherine_Zeta-Jones 0\n",
      "Charles_Moose 0\n",
      "Colin_Powell 0\n",
      "Condoleezza_Rice 0\n",
      "David_Beckham 0\n",
      "David_Nalbandian 0\n",
      "Dick_Cheney 0\n",
      "Dominique_de_Villepin 0\n",
      "Donald_Rumsfeld 0\n",
      "Edmund_Stoiber 0\n",
      "Eduardo_Duhalde 0\n",
      "Fidel_Castro 0\n",
      "George_HW_Bush 0\n",
      "George_Robertson 0\n",
      "George_W_Bush 0\n",
      "Gerhard_Schroeder 0\n",
      "Gloria_Macapagal_Arroyo 0\n",
      "Gonzalo_Sanchez_de_Lozada 0\n",
      "Gordon_Brown 0\n",
      "Gray_Davis 0\n",
      "Guillermo_Coria 0\n",
      "Halle_Berry 0\n",
      "Hamid_Karzai 0\n",
      "Hans_Blix 0\n",
      "Harrison_Ford 0\n",
      "Hillary_Clinton 0\n",
      "Howard_Dean 0\n",
      "Hugo_Chavez 0\n",
      "Hu_Jintao 0\n",
      "Ian_Thorpe 0\n",
      "Igor_Ivanov 0\n",
      "Jackie_Chan 0\n",
      "Jack_Straw 0\n",
      "Jacques_Chirac 0\n",
      "Jacques_Rogge 0\n",
      "James_Blake 0\n",
      "James_Kelly 0\n",
      "Jason_Kidd 0\n",
      "Javier_Solana 0\n",
      "Jean-David_Levitte 0\n",
      "Jean_Charest 0\n",
      "Jean_Chretien 0\n",
      "Jeb_Bush 0\n",
      "Jennifer_Aniston 1\n",
      "Jennifer_Capriati 0\n",
      "Jennifer_Garner 0\n",
      "Jennifer_Lopez 1\n",
      "Jeremy_Greenstock 0\n",
      "Jiang_Zemin 0\n",
      "Jiri_Novak 0\n",
      "Joe_Lieberman 0\n",
      "John_Allen_Muhammad 0\n",
      "John_Ashcroft 0\n",
      "John_Bolton 0\n",
      "John_Howard 0\n",
      "John_Kerry 0\n",
      "John_Negroponte 0\n",
      "John_Paul_II 0\n",
      "John_Snow 0\n",
      "Joschka_Fischer 0\n",
      "Jose_Maria_Aznar 0\n",
      "Juan_Carlos_Ferrero 0\n",
      "Julianne_Moore 0\n",
      "Julie_Gerberding 0\n",
      "Junichiro_Koizumi 0\n",
      "David_Schwimmer 1\n"
     ]
    }
   ],
   "source": [
    "# 1 MEANS PRESENT, 0 MEANS ABSENT\n",
    "for i in classes:\n",
    "    if i in present:\n",
    "        print(classes[i] + \" 1\")\n",
    "    else:\n",
    "        print(classes[i] + \" 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
